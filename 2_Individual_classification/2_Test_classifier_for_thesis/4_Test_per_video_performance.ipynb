{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3925077f-5d96-4013-a127-93d67e0a1e21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: 100%|██████████| 1808/1808 [00:00<00:00, 3427.06video/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Video-level predictions written to: /lisc/data/scratch/becogbio/juarez/test_thesis/Combined_predict_vp_individual/video_level_majority_vote.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "INPUT_CSV = Path(\"/lisc/data/scratch/becogbio/juarez/test_thesis/Combined_predict_vp_individual/combined_predictions_with_video_name.csv\")\n",
    "OUTPUT_CSV = INPUT_CSV.with_name(\"video_level_majority_vote.csv\")\n",
    "\n",
    "def majority_vote(series: pd.Series):\n",
    "    \"\"\"\n",
    "    Returns the most frequent value in a Pandas Series.\n",
    "    In case of ties, the first encountered most-frequent value is returned.\n",
    "    \"\"\"\n",
    "    return series.value_counts().idxmax()\n",
    "\n",
    "def main():\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(INPUT_CSV, dtype=str)\n",
    "\n",
    "    # Sanity check\n",
    "    for col in [\"Video Name\", \"Inddividual_prediction\"]:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing column '{col}' in input CSV.\")\n",
    "\n",
    "    # Prepare results list\n",
    "    results = []\n",
    "\n",
    "    # Group by Video Name manually to use tqdm\n",
    "    grouped = df.groupby(\"Video Name\")\n",
    "    for video_name, group in tqdm(grouped, desc=\"Processing videos\", unit=\"video\"):\n",
    "        winner = majority_vote(group[\"Inddividual_prediction\"])\n",
    "        results.append({\"Video Name\": video_name, \"Majority_Individual_prediction\": winner})\n",
    "\n",
    "    # Create final DataFrame\n",
    "    df_video = pd.DataFrame(results)\n",
    "\n",
    "    # Save\n",
    "    df_video.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"[OK] Video-level predictions written to: {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20039932-4296-4790-8f06-73cd827d54c8",
   "metadata": {},
   "source": [
    "# Per video evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88da80d4-e553-4add-a13e-fc0aea0f319d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     BNU-RPM      0.986     0.973     0.980       149\n",
      "     BNY-RPM      0.918     0.867     0.891        90\n",
      "     BRG-YOM      0.954     0.989     0.971       272\n",
      "     BRK-NOM      0.800     0.889     0.842        27\n",
      "     EYB-RPM      0.970     0.987     0.978       226\n",
      "     GBM-ORY      0.958     0.944     0.951       144\n",
      "     GBY-ORM      0.924     0.964     0.944       165\n",
      "     OEB-RPM      0.959     0.922     0.940        51\n",
      "     OGY-BRM      0.986     0.892     0.937       158\n",
      "     ORB-UYM      0.828     0.972     0.895       109\n",
      "     OUB-RPM      0.902     0.846     0.873        65\n",
      "     OYR-BGM      0.933     0.906     0.920       139\n",
      "     RGY-BOM      0.681     0.542     0.604        59\n",
      "     RYO-BGM      0.872     0.965     0.916        85\n",
      "      YM-OBR      0.925     0.949     0.937        39\n",
      "     YRU-POM      1.000     0.767     0.868        30\n",
      "\n",
      "    accuracy                          0.931      1808\n",
      "   macro avg      0.912     0.898     0.903      1808\n",
      "weighted avg      0.931     0.931     0.930      1808\n",
      "\n",
      "[OK] Per-bird summary written to: /lisc/data/scratch/becogbio/juarez/test_thesis/2_individual_classifier/test_on_test_set/per_video/video_level_summary_per_bird.csv\n",
      "[OK] Evaluation file written to: /lisc/data/scratch/becogbio/juarez/test_thesis/2_individual_classifier/test_on_test_set/per_video/video_level_evaluation.csv\n",
      "[OK] Confusion matrix saved to: /lisc/data/scratch/becogbio/juarez/test_thesis/2_individual_classifier/test_on_test_set/per_video/video_level_confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "VIDEO_PRED_CSV = Path(\"/lisc/data/scratch/becogbio/juarez/test_thesis/Combined_predict_vp_individual/video_level_majority_vote.csv\")\n",
    "META_CSV = Path(\"/lisc/data/scratch/becogbio/juarez/test_thesis/0_raw_videos/test_videos/test_videos_metadata.csv\")\n",
    "OUTPUT_EVAL = Path(\"/lisc/data/scratch/becogbio/juarez/test_thesis/2_individual_classifier/test_on_test_set/per_video/video_level_evaluation.csv\")\n",
    "OUTPUT_SUMMARY = Path(\"/lisc/data/scratch/becogbio/juarez/test_thesis/2_individual_classifier/test_on_test_set/per_video/video_level_summary_per_bird.csv\")\n",
    "OUTPUT_CM = Path(\"/lisc/data/scratch/becogbio/juarez/test_thesis/2_individual_classifier/test_on_test_set/per_video/video_level_confusion_matrix.png\")\n",
    "\n",
    "def main():\n",
    "    # Load predictions\n",
    "    df_pred = pd.read_csv(VIDEO_PRED_CSV, dtype=str)\n",
    "    if not {\"Video Name\", \"Majority_Individual_prediction\"} <= set(df_pred.columns):\n",
    "        raise ValueError(\"Predictions CSV must have 'Video Name' and 'Majority_Individual_prediction' columns.\")\n",
    "\n",
    "    # Load metadata\n",
    "    df_meta = pd.read_csv(META_CSV, dtype=str)\n",
    "    if not {\"Video_ID\", \"Bird_ID\"} <= set(df_meta.columns):\n",
    "        raise ValueError(\"Metadata CSV must have 'Video_ID' and 'Bird_ID' columns.\")\n",
    "\n",
    "    # Merge predictions with ground truth\n",
    "    df_eval = pd.merge(df_pred, df_meta, left_on=\"Video Name\", right_on=\"Video_ID\", how=\"inner\")\n",
    "    if df_eval.empty:\n",
    "        raise ValueError(\"No matches found between predictions and metadata!\")\n",
    "\n",
    "    # Evaluate\n",
    "    y_true = df_eval[\"Bird_ID\"]\n",
    "    y_pred = df_eval[\"Majority_Individual_prediction\"]\n",
    "\n",
    "    # --- Classification report ---\n",
    "    report = classification_report(y_true, y_pred, digits=3)\n",
    "    print(\"\\n=== Classification Report ===\")\n",
    "    print(report)\n",
    "\n",
    "    # --- Per-bird summary table ---\n",
    "    summary_records = []\n",
    "    labels = sorted(df_eval[\"Bird_ID\"].unique())\n",
    "    p, r, f1, support = precision_recall_fscore_support(y_true, y_pred, labels=labels, zero_division=0)\n",
    "\n",
    "    for bird, prec, rec, f1s, sup in zip(labels, p, r, f1, support):\n",
    "        n_correct = ((df_eval[\"Bird_ID\"] == bird) & (df_eval[\"Majority_Individual_prediction\"] == bird)).sum()\n",
    "        summary_records.append({\n",
    "            \"Bird_ID\": bird,\n",
    "            \"n_videos\": sup,\n",
    "            \"n_correct\": n_correct,\n",
    "            \"accuracy\": n_correct / sup if sup > 0 else 0.0,\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"f1_score\": f1s,\n",
    "        })\n",
    "\n",
    "    df_summary = pd.DataFrame(summary_records)\n",
    "    df_summary.to_csv(OUTPUT_SUMMARY, index=False)\n",
    "    print(f\"[OK] Per-bird summary written to: {OUTPUT_SUMMARY}\")\n",
    "\n",
    "    # Save merged results for traceability\n",
    "    df_eval.to_csv(OUTPUT_EVAL, index=False)\n",
    "    print(f\"[OK] Evaluation file written to: {OUTPUT_EVAL}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greys\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Ground Truth\")\n",
    "    plt.title(\"Video-level Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_CM)\n",
    "    plt.close()\n",
    "    print(f\"[OK] Confusion matrix saved to: {OUTPUT_CM}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f7c7d5-bf5f-4948-b013-4da31a2a5180",
   "metadata": {},
   "source": [
    "# Per video evaluation PER VIEWPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a7a4b28-00d7-49a4-8987-82042c2d8efb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Per-video (per-viewpoint + overall) majority predictions saved to: /lisc/data/scratch/becogbio/juarez/test_thesis/2_individual_classifier/test_on_test_set/per_video_per_viewpoint/video_level_majority_per_viewpointt.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- PATHS ---\n",
    "INPUT_CSV = \"/lisc/data/scratch/becogbio/juarez/test_thesis/Combined_predict_vp_individual/combined_predictions_with_video_name.csv\"\n",
    "OUTPUT_CSV = \"/lisc/data/scratch/becogbio/juarez/test_thesis/2_individual_classifier/test_on_test_set/per_video_per_viewpoint/video_level_majority_per_viewpointt.csv\"\n",
    "\n",
    "# --- LOAD DATA ---\n",
    "df = pd.read_csv(INPUT_CSV, dtype=str)\n",
    "\n",
    "# --- MAJORITY VOTING FUNCTION ---\n",
    "def majority_vote(labels):\n",
    "    \"\"\"Return the most common label in a group.\"\"\"\n",
    "    return labels.value_counts().idxmax()\n",
    "\n",
    "# --- PER-VIDEO, PER-VIEWPOINT MAJORITY ---\n",
    "grouped = df.groupby([\"Video Name\", \"Viewpoint_prediction\"])[\"Inddividual_prediction\"]\n",
    "majority = grouped.apply(majority_vote).reset_index()\n",
    "\n",
    "# --- PIVOT TO GET ONE COLUMN PER VIEWPOINT ---\n",
    "result = majority.pivot(\n",
    "    index=\"Video Name\",\n",
    "    columns=\"Viewpoint_prediction\",\n",
    "    values=\"Inddividual_prediction\"\n",
    ").reset_index()\n",
    "\n",
    "# --- ADD OVERALL MAJORITY (ALL VIEWPOINTS) ---\n",
    "overall_majority = df.groupby(\"Video Name\")[\"Inddividual_prediction\"].apply(majority_vote)\n",
    "result[\"all_viewpoints\"] = result[\"Video Name\"].map(overall_majority)\n",
    "\n",
    "# --- SAVE OUTPUT ---\n",
    "result.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"[OK] Per-video (per-viewpoint + overall) majority predictions saved to: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986704ed-9ee1-4039-97f7-e8cae07e7cfa",
   "metadata": {},
   "source": [
    "# Per viewpoint majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c38c9baa-f3e2-42b8-98ac-3a3eddd92c80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Viewpoint 'back': using 1265/1808 videos (70.0% coverage)\n",
      "[INFO] Viewpoint 'front': using 1076/1808 videos (59.5% coverage)\n",
      "[INFO] Viewpoint 'left_side': using 1062/1808 videos (58.7% coverage)\n",
      "[INFO] Viewpoint 'right_side': using 961/1808 videos (53.2% coverage)\n",
      "[INFO] Viewpoint 'all_viewpoints': using 1808/1808 videos (100.0% coverage)\n",
      "[OK] Saved per-bird F1-scores per viewpoint to: /lisc/data/scratch/becogbio/juarez/test_thesis/Combined_predict_vp_individual/f1_scores_per_bird_per_viewpoint.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# --- PATHS ---\n",
    "PRED_CSV = \"/lisc/data/scratch/becogbio/juarez/test_thesis/Combined_predict_vp_individual/video_level_majority_per_viewpointt.csv\"\n",
    "META_CSV = \"/lisc/data/scratch/becogbio/juarez/test_thesis/0_raw_videos/test_videos/test_videos_metadata.csv\"\n",
    "OUTPUT_CSV = \"/lisc/data/scratch/becogbio/juarez/test_thesis/Combined_predict_vp_individual/f1_scores_per_bird_per_viewpoint.csv\"\n",
    "\n",
    "# --- LOAD ---\n",
    "df_pred = pd.read_csv(PRED_CSV, dtype=str)\n",
    "df_meta = pd.read_csv(META_CSV, dtype=str)\n",
    "df = pd.merge(df_pred, df_meta, left_on=\"Video Name\", right_on=\"Video_ID\", how=\"inner\")\n",
    "if df.empty:\n",
    "    raise ValueError(\"No matching videos between predictions and metadata!\")\n",
    "\n",
    "viewpoint_cols = [c for c in df_pred.columns if c != \"Video Name\"]\n",
    "birds = sorted(df[\"Bird_ID\"].unique())\n",
    "summary = pd.DataFrame({\"Bird_ID\": birds})\n",
    "\n",
    "for vp in viewpoint_cols:\n",
    "    sub = df.dropna(subset=[vp])\n",
    "    coverage = len(sub) / len(df)\n",
    "    print(f\"[INFO] Viewpoint '{vp}': using {len(sub)}/{len(df)} videos ({coverage:.1%} coverage)\")\n",
    "\n",
    "    y_true = sub[\"Bird_ID\"].astype(str)\n",
    "    y_pred = sub[vp].astype(str)\n",
    "\n",
    "    _, _, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=birds, zero_division=0\n",
    "    )\n",
    "\n",
    "    summary[vp] = f1  # add as a new column\n",
    "\n",
    "summary.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"[OK] Saved per-bird F1-scores per viewpoint to: {OUTPUT_CSV}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
