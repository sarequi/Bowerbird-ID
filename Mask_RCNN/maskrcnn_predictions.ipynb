{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "confThreshold = 0.7  # filters out detections with confidence <50%\n",
    "maskThreshold = 0.4  # keeps pixels with probability >30% in the mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was trained on the MS COCO dataset, which contains many object categories. Each detected object will be assigned a unique color for the mask. Thus, the following snippet...\n",
    "* Loads the names of those object categories into a list\n",
    "* Loads the colors and converts them to an array format that can be used to visually apply the masks\n",
    "* Loads the pre-trained TensorFlow model (Mask-RCNN) into OpenCV's DNN module\n",
    "* Sets the backend and target device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads class names from the specified file \n",
    "classesFile = \"/Users/sarah/Mask_RCNN/mscoco_labels.names\"\n",
    "classes = None\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "color = [255, 0, 0]  # Hardcoded the color as there will only be one class\n",
    "\n",
    "textGraph = \"/Users/sarah/Mask_RCNN/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\" # defines the structure of the network\n",
    "modelWeights = \"/Users/sarah/Mask_RCNN/frozen_inference_graph.pb\" # contains the pre-trained weights of the model\n",
    "\n",
    "# OpenCV’s DNN module loads the pre-trained Mask R-CNN network using the TensorFlow format\n",
    "net = cv.dnn.readNetFromTensorflow(modelWeights, textGraph)\n",
    "\n",
    "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV) # sets the backend as OpenCV\n",
    "net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU) # sets the target device to CPU for inference (can be changed to GPU) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draws the predicted bounding box, colorize and show the mask on the image\n",
    "def drawBox(frame, classId, conf, left, top, right, bottom, classMask):\n",
    "    cv.rectangle(frame, (left, top), (right, bottom), (255, 178, 50), 3)  # thickness 3, orange color (255, 178, 50)\n",
    "    label = '%.2f' % conf  # prints a label with the confidence score\n",
    "\n",
    "    labelSize, baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.5, 1)  # calculates text label size\n",
    "    top = max(top, labelSize[1])\n",
    "    cv.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (255, 255, 255), cv.FILLED)  # draws a white rectangle as bg\n",
    "    cv.putText(frame, label, (left, top), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 1)  # prints text (confidence score) in black\n",
    "\n",
    "    # resizes the mask, thresholds, colorize and apply it on the image\n",
    "    classMask = cv.resize(classMask, (right - left + 1, bottom - top + 1))  # resizes the mask to fit the bbox\n",
    "    mask = (classMask > maskThreshold)  # thresholds the mask so that only areas above the maskThreshold are kept\n",
    "    roi = frame[top:bottom+1, left:right+1][mask]  # applies the mask to the region of interest (ROI) in the frame\n",
    "\n",
    "    color = [255, 0, 0]  # Use a fixed color (blue)\n",
    "\n",
    "    # colors the masked region with a blend of 30% of the mask's color and 70% of the original region\n",
    "    frame[top:bottom+1, left:right+1][mask] = ([0.3*color[0], 0.3*color[1], 0.3*color[2]] + 0.7 * roi).astype(np.uint8)\n",
    "\n",
    "    # draws the contours on the image\n",
    "    mask = mask.astype(np.uint8)  # converts the mask to a binary format (0 or 1)\n",
    "    contours, hierarchy = cv.findContours(mask, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)  # finds contours and returns 2 values (contours, hierarchy)\n",
    "    cv.drawContours(frame[top:bottom+1, left:right+1], contours, -1, color, 3, cv.LINE_8, hierarchy, 100)  # draws contours using the fixed color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing function\n",
    "For each frame, extracts the bounding box and mask for each detected object. Output size of masks is NxCxHxW where:\n",
    "* N - number of detected boxes\n",
    "* C - number of classes (excluding background)\n",
    "* HxW - segmentation mask size (e.g., 15x15 in this model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(boxes, masks):\n",
    "    # numClasses = masks.shape[1] # can be accessed if needed\n",
    "    numDetections = boxes.shape[2]\n",
    "    \n",
    "    # Get frame's height and width\n",
    "    frameH = frame.shape[0]\n",
    "    frameW = frame.shape[1]\n",
    "    \n",
    "    for i in range(numDetections):\n",
    "        box = boxes[0, 0, i] # gets the bounding box information\n",
    "        mask = masks[i] # gets the object's mask\n",
    "        score = box[2] # confidence score of the detected object\n",
    "\n",
    "        # only consider detections above the confidence threshold\n",
    "        if score > confThreshold:\n",
    "            classId = int(box[1]) # gets the class ID for the detected object\n",
    "            \n",
    "            # extracts bbox coordinates (scaled to the frame size)\n",
    "            left = int(frameW * box[3])\n",
    "            top = int(frameH * box[4])\n",
    "            right = int(frameW * box[5])\n",
    "            bottom = int(frameH * box[6])\n",
    "            \n",
    "            # ensures the coords are within the frame boundaries\n",
    "            left = max(0, min(left, frameW - 1))\n",
    "            top = max(0, min(top, frameH - 1))\n",
    "            right = max(0, min(right, frameW - 1))\n",
    "            bottom = max(0, min(bottom, frameH - 1))\n",
    "            \n",
    "            # extracts the mask for the object's detected class\n",
    "            classMask = mask[classId]\n",
    "            \n",
    "            drawBox(frame, classId, score, left, top, right, bottom, classMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input handling and output initialization\n",
    "\n",
    "This script processes an image or video file, saving the output as a .png for images or an .mp4 for videos. For video inputs, the script also initializes a video writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3/11 [00:04<00:11,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store ain't an image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:14<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "# input folder (containing the images) and output folder (for saving processed images)\n",
    "inputFolder = \"/Users/sarah/Bowerbird-ID/MegaDetector/output_cropped_frames\"\n",
    "outputFolder = \"/Users/sarah/Bowerbird-ID/Mask_RCNN/predictions\"\n",
    "\n",
    "for imageFile in tqdm(os.listdir(inputFolder)):\n",
    "    if not imageFile.lower().endswith('.png'):\n",
    "        print(f\"{imageFile} ain't an image\")\n",
    "        continue\n",
    "    imagePath = os.path.join(inputFolder, imageFile)\n",
    "    \n",
    "    frame = cv.imread(imagePath)\n",
    "\n",
    "    outputFile = os.path.join(outputFolder, os.path.basename(imageFile)[:-4] + 'pred.png')\n",
    "\n",
    "    # creates a 4D blob from the image for Mask R-CNN\n",
    "    blob = cv.dnn.blobFromImage(frame, swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # runs the forward pass to get output from the output layers\n",
    "    boxes, masks = net.forward(['detection_out_final', 'detection_masks'])\n",
    "\n",
    "    # post-process the detections (custom function to handle boxes and masks)\n",
    "    postprocess(boxes, masks)\n",
    "\n",
    "    # prints efficiency info (inference time)\n",
    "    t, _ = net.getPerfProfile()\n",
    "    label = 'Mask-RCNN : Inference time: %.2f ms' % (t * 1000.0 / cv.getTickFrequency())\n",
    "    cv.putText(frame, label, (0, 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
    "\n",
    "    cv.imwrite(outputFile, frame.astype(np.uint8)) # saves the output image \n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bower_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
